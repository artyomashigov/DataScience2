{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Kaggle competition has been launched, please register using this [link.](https://www.kaggle.com/t/f79b637ede074e70a233661b4614083c)\n",
    "\n",
    "You will find the training and test data in the data section of the competition, along with a description of the features. You will need to build models on the training data and make predictions on the test data and submit your solutions to Kaggle. You will also find a sample solution file in the data section that shows the format you will need to use for your own submissions.\n",
    "\n",
    "The deadline for Kaggle solutions is 8PM on 19 April. You will be graded primarily on the basis of your work and how clearly you explain your methods and results. Those in the top three in the competition will receive some extra points. I expect you to experiment with all the methods we have covered: linear models, random forest, gradient boosting, neural networks + parameter tuning, feature engineering.\n",
    "\n",
    "You will see the public score of your best model on the leaderboard. A private dataset will be used to evaluate the final performance of your model to avoid overfitting based on the leaderboard.\n",
    "\n",
    "You should also submit to Moodle the documentation (ipynb and pdf) of your work, including exploratory data analysis, data cleaning, parameter tuning and evaluation. Aim for concise explanations.\n",
    "\n",
    "Feel free to ask questions about the task in Slack. The Kaggle competition is already open, please start working on it and submitting solutions (you cannot submit more than 5 solutions per day).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The plan\n",
    "\n",
    "Our plan for the Kaggle competition involves a systematic approach to model development and optimization. Initially, we will split the provided 'train' dataframe into two segments to serve as our training and validation sets. We intend to build and evaluate different predictive models—such as logistic regression, random forests, and gradient boosting machines—focusing on the AUC metric to determine their performance. The model with the highest AUC on our validation set will be selected for further refinement. After the initial modeling phase, we will engage in feature engineering to enhance the dataset, followed by rebuilding and re-evaluating the models with the new features. The best-performing model from this second phase will then be applied to the external validation set. Finally, we will prepare and submit our predictions in the required format (article_id and score) to Kaggle, ensuring they align with the competition's guidelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# show max columns and rows\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29733, 61)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>average_token_length</th>\n",
       "      <th>num_keywords</th>\n",
       "      <th>data_channel_is_lifestyle</th>\n",
       "      <th>data_channel_is_entertainment</th>\n",
       "      <th>data_channel_is_bus</th>\n",
       "      <th>data_channel_is_socmed</th>\n",
       "      <th>data_channel_is_tech</th>\n",
       "      <th>data_channel_is_world</th>\n",
       "      <th>kw_min_min</th>\n",
       "      <th>kw_max_min</th>\n",
       "      <th>kw_avg_min</th>\n",
       "      <th>kw_min_max</th>\n",
       "      <th>kw_max_max</th>\n",
       "      <th>kw_avg_max</th>\n",
       "      <th>kw_min_avg</th>\n",
       "      <th>kw_max_avg</th>\n",
       "      <th>kw_avg_avg</th>\n",
       "      <th>self_reference_min_shares</th>\n",
       "      <th>self_reference_max_shares</th>\n",
       "      <th>self_reference_avg_sharess</th>\n",
       "      <th>weekday_is_monday</th>\n",
       "      <th>weekday_is_tuesday</th>\n",
       "      <th>weekday_is_wednesday</th>\n",
       "      <th>weekday_is_thursday</th>\n",
       "      <th>weekday_is_friday</th>\n",
       "      <th>weekday_is_saturday</th>\n",
       "      <th>weekday_is_sunday</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>LDA_00</th>\n",
       "      <th>LDA_01</th>\n",
       "      <th>LDA_02</th>\n",
       "      <th>LDA_03</th>\n",
       "      <th>LDA_04</th>\n",
       "      <th>global_subjectivity</th>\n",
       "      <th>global_sentiment_polarity</th>\n",
       "      <th>global_rate_positive_words</th>\n",
       "      <th>global_rate_negative_words</th>\n",
       "      <th>rate_positive_words</th>\n",
       "      <th>rate_negative_words</th>\n",
       "      <th>avg_positive_polarity</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>is_popular</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>594</td>\n",
       "      <td>9</td>\n",
       "      <td>702</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.620438</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.790598</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2900.0</td>\n",
       "      <td>753.875</td>\n",
       "      <td>2900</td>\n",
       "      <td>690400</td>\n",
       "      <td>194850.0</td>\n",
       "      <td>2635.188119</td>\n",
       "      <td>5109.090909</td>\n",
       "      <td>3411.008319</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>6500.0</td>\n",
       "      <td>3850.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.453017</td>\n",
       "      <td>0.025031</td>\n",
       "      <td>0.025053</td>\n",
       "      <td>0.025027</td>\n",
       "      <td>0.471872</td>\n",
       "      <td>0.499743</td>\n",
       "      <td>0.224620</td>\n",
       "      <td>0.047009</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.452328</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.153395</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>346</td>\n",
       "      <td>8</td>\n",
       "      <td>1197</td>\n",
       "      <td>0.470143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666209</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>4.622389</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>417.0</td>\n",
       "      <td>120.000</td>\n",
       "      <td>0</td>\n",
       "      <td>843300</td>\n",
       "      <td>221250.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4221.436364</td>\n",
       "      <td>2393.577920</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>68300.0</td>\n",
       "      <td>21600.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.033338</td>\n",
       "      <td>0.034222</td>\n",
       "      <td>0.033336</td>\n",
       "      <td>0.865673</td>\n",
       "      <td>0.033430</td>\n",
       "      <td>0.509674</td>\n",
       "      <td>0.169761</td>\n",
       "      <td>0.060986</td>\n",
       "      <td>0.020886</td>\n",
       "      <td>0.744898</td>\n",
       "      <td>0.255102</td>\n",
       "      <td>0.434561</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.308167</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>484</td>\n",
       "      <td>9</td>\n",
       "      <td>214</td>\n",
       "      <td>0.618090</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.748092</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.476636</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>512.0</td>\n",
       "      <td>138.625</td>\n",
       "      <td>2400</td>\n",
       "      <td>843300</td>\n",
       "      <td>184962.5</td>\n",
       "      <td>945.500000</td>\n",
       "      <td>3602.455629</td>\n",
       "      <td>2481.347103</td>\n",
       "      <td>331.0</td>\n",
       "      <td>331.0</td>\n",
       "      <td>331.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.025767</td>\n",
       "      <td>0.025002</td>\n",
       "      <td>0.025002</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.899229</td>\n",
       "      <td>0.311717</td>\n",
       "      <td>0.060404</td>\n",
       "      <td>0.042056</td>\n",
       "      <td>0.028037</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.254562</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>-0.141667</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>639</td>\n",
       "      <td>8</td>\n",
       "      <td>249</td>\n",
       "      <td>0.621951</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.664740</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5.180723</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>717.0</td>\n",
       "      <td>146.600</td>\n",
       "      <td>0</td>\n",
       "      <td>617900</td>\n",
       "      <td>221150.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4612.708333</td>\n",
       "      <td>2920.744778</td>\n",
       "      <td>2900.0</td>\n",
       "      <td>8800.0</td>\n",
       "      <td>5866.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.373002</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.526997</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.387522</td>\n",
       "      <td>-0.006684</td>\n",
       "      <td>0.036145</td>\n",
       "      <td>0.016064</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.231818</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>177</td>\n",
       "      <td>12</td>\n",
       "      <td>1219</td>\n",
       "      <td>0.397841</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.583578</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4.659557</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>60.0</td>\n",
       "      <td>25.250</td>\n",
       "      <td>3100</td>\n",
       "      <td>843300</td>\n",
       "      <td>263875.0</td>\n",
       "      <td>844.562500</td>\n",
       "      <td>3529.366510</td>\n",
       "      <td>2250.688809</td>\n",
       "      <td>627.0</td>\n",
       "      <td>627.0</td>\n",
       "      <td>627.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.799995</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050004</td>\n",
       "      <td>0.457970</td>\n",
       "      <td>0.077511</td>\n",
       "      <td>0.025431</td>\n",
       "      <td>0.012305</td>\n",
       "      <td>0.673913</td>\n",
       "      <td>0.326087</td>\n",
       "      <td>0.380401</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>-0.441111</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timedelta  n_tokens_title  n_tokens_content  n_unique_tokens  \\\n",
       "0        594               9               702         0.454545   \n",
       "1        346               8              1197         0.470143   \n",
       "2        484               9               214         0.618090   \n",
       "3        639               8               249         0.621951   \n",
       "4        177              12              1219         0.397841   \n",
       "\n",
       "   n_non_stop_words  n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  \\\n",
       "0               1.0                  0.620438         11               2   \n",
       "1               1.0                  0.666209         21               6   \n",
       "2               1.0                  0.748092          5               2   \n",
       "3               1.0                  0.664740         16               5   \n",
       "4               1.0                  0.583578         21               1   \n",
       "\n",
       "   num_imgs  num_videos  average_token_length  num_keywords  \\\n",
       "0         1           0              4.790598             8   \n",
       "1         2          13              4.622389             6   \n",
       "2         1           0              4.476636             8   \n",
       "3         8           0              5.180723             6   \n",
       "4         1           2              4.659557             4   \n",
       "\n",
       "   data_channel_is_lifestyle  data_channel_is_entertainment  \\\n",
       "0                          0                              0   \n",
       "1                          0                              1   \n",
       "2                          0                              0   \n",
       "3                          0                              0   \n",
       "4                          0                              0   \n",
       "\n",
       "   data_channel_is_bus  data_channel_is_socmed  data_channel_is_tech  \\\n",
       "0                    1                       0                     0   \n",
       "1                    0                       0                     0   \n",
       "2                    0                       0                     1   \n",
       "3                    0                       0                     0   \n",
       "4                    0                       0                     0   \n",
       "\n",
       "   data_channel_is_world  kw_min_min  kw_max_min  kw_avg_min  kw_min_max  \\\n",
       "0                      0           4      2900.0     753.875        2900   \n",
       "1                      0          -1       417.0     120.000           0   \n",
       "2                      0           4       512.0     138.625        2400   \n",
       "3                      0           4       717.0     146.600           0   \n",
       "4                      1          -1        60.0      25.250        3100   \n",
       "\n",
       "   kw_max_max  kw_avg_max   kw_min_avg   kw_max_avg   kw_avg_avg  \\\n",
       "0      690400    194850.0  2635.188119  5109.090909  3411.008319   \n",
       "1      843300    221250.0     0.000000  4221.436364  2393.577920   \n",
       "2      843300    184962.5   945.500000  3602.455629  2481.347103   \n",
       "3      617900    221150.0     0.000000  4612.708333  2920.744778   \n",
       "4      843300    263875.0   844.562500  3529.366510  2250.688809   \n",
       "\n",
       "   self_reference_min_shares  self_reference_max_shares  \\\n",
       "0                     1200.0                     6500.0   \n",
       "1                     1900.0                    68300.0   \n",
       "2                      331.0                      331.0   \n",
       "3                     2900.0                     8800.0   \n",
       "4                      627.0                      627.0   \n",
       "\n",
       "   self_reference_avg_sharess  weekday_is_monday  weekday_is_tuesday  \\\n",
       "0                 3850.000000                  0                   0   \n",
       "1                21600.000000                  1                   0   \n",
       "2                  331.000000                  0                   0   \n",
       "3                 5866.666667                  0                   1   \n",
       "4                  627.000000                  0                   1   \n",
       "\n",
       "   weekday_is_wednesday  weekday_is_thursday  weekday_is_friday  \\\n",
       "0                     0                    0                  1   \n",
       "1                     0                    0                  0   \n",
       "2                     1                    0                  0   \n",
       "3                     0                    0                  0   \n",
       "4                     0                    0                  0   \n",
       "\n",
       "   weekday_is_saturday  weekday_is_sunday  is_weekend    LDA_00    LDA_01  \\\n",
       "0                    0                  0           0  0.453017  0.025031   \n",
       "1                    0                  0           0  0.033338  0.034222   \n",
       "2                    0                  0           0  0.025767  0.025002   \n",
       "3                    0                  0           0  0.033333  0.373002   \n",
       "4                    0                  0           0  0.050001  0.050000   \n",
       "\n",
       "     LDA_02    LDA_03    LDA_04  global_subjectivity  \\\n",
       "0  0.025053  0.025027  0.471872             0.499743   \n",
       "1  0.033336  0.865673  0.033430             0.509674   \n",
       "2  0.025002  0.025000  0.899229             0.311717   \n",
       "3  0.033333  0.526997  0.033333             0.387522   \n",
       "4  0.799995  0.050000  0.050004             0.457970   \n",
       "\n",
       "   global_sentiment_polarity  global_rate_positive_words  \\\n",
       "0                   0.224620                    0.047009   \n",
       "1                   0.169761                    0.060986   \n",
       "2                   0.060404                    0.042056   \n",
       "3                  -0.006684                    0.036145   \n",
       "4                   0.077511                    0.025431   \n",
       "\n",
       "   global_rate_negative_words  rate_positive_words  rate_negative_words  \\\n",
       "0                    0.012821             0.785714             0.214286   \n",
       "1                    0.020886             0.744898             0.255102   \n",
       "2                    0.028037             0.600000             0.400000   \n",
       "3                    0.016064             0.692308             0.307692   \n",
       "4                    0.012305             0.673913             0.326087   \n",
       "\n",
       "   avg_positive_polarity  min_positive_polarity  max_positive_polarity  \\\n",
       "0               0.452328                   0.10               1.000000   \n",
       "1               0.434561                   0.05               1.000000   \n",
       "2               0.254562                   0.10               0.433333   \n",
       "3               0.231818                   0.10               0.500000   \n",
       "4               0.380401                   0.05               0.800000   \n",
       "\n",
       "   avg_negative_polarity  min_negative_polarity  max_negative_polarity  \\\n",
       "0              -0.153395                   -0.4                  -0.10   \n",
       "1              -0.308167                   -1.0                  -0.10   \n",
       "2              -0.141667                   -0.2                  -0.05   \n",
       "3              -0.500000                   -0.8                  -0.40   \n",
       "4              -0.441111                   -1.0                  -0.05   \n",
       "\n",
       "   title_subjectivity  title_sentiment_polarity  abs_title_subjectivity  \\\n",
       "0                 0.0                       0.0                     0.5   \n",
       "1                 0.0                       0.0                     0.5   \n",
       "2                 0.0                       0.0                     0.5   \n",
       "3                 0.0                       0.0                     0.5   \n",
       "4                 0.0                       0.0                     0.5   \n",
       "\n",
       "   abs_title_sentiment_polarity  is_popular  article_id  \n",
       "0                           0.0           0           1  \n",
       "1                           0.0           0           3  \n",
       "2                           0.0           0           5  \n",
       "3                           0.0           0           6  \n",
       "4                           0.0           0           7  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the data\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "# check the shape\n",
    "print(train.shape)\n",
    "# print first 5 rows\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29733 entries, 0 to 29732\n",
      "Data columns (total 61 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   timedelta                      29733 non-null  int64  \n",
      " 1   n_tokens_title                 29733 non-null  int64  \n",
      " 2   n_tokens_content               29733 non-null  int64  \n",
      " 3   n_unique_tokens                29733 non-null  float64\n",
      " 4   n_non_stop_words               29733 non-null  float64\n",
      " 5   n_non_stop_unique_tokens       29733 non-null  float64\n",
      " 6   num_hrefs                      29733 non-null  int64  \n",
      " 7   num_self_hrefs                 29733 non-null  int64  \n",
      " 8   num_imgs                       29733 non-null  int64  \n",
      " 9   num_videos                     29733 non-null  int64  \n",
      " 10  average_token_length           29733 non-null  float64\n",
      " 11  num_keywords                   29733 non-null  int64  \n",
      " 12  data_channel_is_lifestyle      29733 non-null  int64  \n",
      " 13  data_channel_is_entertainment  29733 non-null  int64  \n",
      " 14  data_channel_is_bus            29733 non-null  int64  \n",
      " 15  data_channel_is_socmed         29733 non-null  int64  \n",
      " 16  data_channel_is_tech           29733 non-null  int64  \n",
      " 17  data_channel_is_world          29733 non-null  int64  \n",
      " 18  kw_min_min                     29733 non-null  int64  \n",
      " 19  kw_max_min                     29733 non-null  float64\n",
      " 20  kw_avg_min                     29733 non-null  float64\n",
      " 21  kw_min_max                     29733 non-null  int64  \n",
      " 22  kw_max_max                     29733 non-null  int64  \n",
      " 23  kw_avg_max                     29733 non-null  float64\n",
      " 24  kw_min_avg                     29733 non-null  float64\n",
      " 25  kw_max_avg                     29733 non-null  float64\n",
      " 26  kw_avg_avg                     29733 non-null  float64\n",
      " 27  self_reference_min_shares      29733 non-null  float64\n",
      " 28  self_reference_max_shares      29733 non-null  float64\n",
      " 29  self_reference_avg_sharess     29733 non-null  float64\n",
      " 30  weekday_is_monday              29733 non-null  int64  \n",
      " 31  weekday_is_tuesday             29733 non-null  int64  \n",
      " 32  weekday_is_wednesday           29733 non-null  int64  \n",
      " 33  weekday_is_thursday            29733 non-null  int64  \n",
      " 34  weekday_is_friday              29733 non-null  int64  \n",
      " 35  weekday_is_saturday            29733 non-null  int64  \n",
      " 36  weekday_is_sunday              29733 non-null  int64  \n",
      " 37  is_weekend                     29733 non-null  int64  \n",
      " 38  LDA_00                         29733 non-null  float64\n",
      " 39  LDA_01                         29733 non-null  float64\n",
      " 40  LDA_02                         29733 non-null  float64\n",
      " 41  LDA_03                         29733 non-null  float64\n",
      " 42  LDA_04                         29733 non-null  float64\n",
      " 43  global_subjectivity            29733 non-null  float64\n",
      " 44  global_sentiment_polarity      29733 non-null  float64\n",
      " 45  global_rate_positive_words     29733 non-null  float64\n",
      " 46  global_rate_negative_words     29733 non-null  float64\n",
      " 47  rate_positive_words            29733 non-null  float64\n",
      " 48  rate_negative_words            29733 non-null  float64\n",
      " 49  avg_positive_polarity          29733 non-null  float64\n",
      " 50  min_positive_polarity          29733 non-null  float64\n",
      " 51  max_positive_polarity          29733 non-null  float64\n",
      " 52  avg_negative_polarity          29733 non-null  float64\n",
      " 53  min_negative_polarity          29733 non-null  float64\n",
      " 54  max_negative_polarity          29733 non-null  float64\n",
      " 55  title_subjectivity             29733 non-null  float64\n",
      " 56  title_sentiment_polarity       29733 non-null  float64\n",
      " 57  abs_title_subjectivity         29733 non-null  float64\n",
      " 58  abs_title_sentiment_polarity   29733 non-null  float64\n",
      " 59  is_popular                     29733 non-null  int64  \n",
      " 60  article_id                     29733 non-null  int64  \n",
      "dtypes: float64(34), int64(27)\n",
      "memory usage: 13.8 MB\n"
     ]
    }
   ],
   "source": [
    "# check info\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently we don't have any missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Models\n",
    "\n",
    "- Logistic Regression\n",
    "- Lasso Regression\n",
    "- Random Forest\n",
    "- Gradient Boosting Machine (GBM)\n",
    "- Neural Network\n",
    "- Explainable Boosting Machine (EBM)\n",
    "- Support Vector Machine (SVM)\n",
    "- k-Nearest Neighbors (k-NN)\n",
    "- XGBoost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model a1: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimal Features Model - AUC Train: 0.5474924736067324, AUC Validation: 0.561370603870939\n",
      "Moderate Features Model - AUC Train: 0.6039263417730092, AUC Validation: 0.6335697293916618\n",
      "Comprehensive Features Model - AUC Train: 0.6925358504255668, AUC Validation: 0.7133059337272026\n"
     ]
    }
   ],
   "source": [
    "# define a random state\n",
    "prng = np.random.RandomState(20240418)\n",
    "\n",
    "# define the traget and features\n",
    "X = train.drop('is_popular', axis=1)\n",
    "y = train['is_popular']\n",
    "\n",
    "# Split data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=prng)\n",
    "\n",
    "# Select features for each model\n",
    "# Minimal feature model (select a few you think are most important)\n",
    "features_minimal = ['n_tokens_title', 'n_tokens_content', 'num_hrefs']\n",
    "\n",
    "# Moderate feature model (a larger set of features)\n",
    "features_moderate = ['n_tokens_title', 'n_tokens_content', 'num_hrefs', 'num_imgs', 'num_videos', 'average_token_length']\n",
    "\n",
    "# All features for the comprehensive model\n",
    "features_comprehensive = list(X_train.columns)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'Minimal Features Model': LogisticRegression(max_iter=1000),\n",
    "    'Moderate Features Model': LogisticRegression(max_iter=1000),\n",
    "    'Comprehensive Features Model': LogisticRegression(max_iter=1000)\n",
    "}\n",
    "\n",
    "# Dictionary to store AUC scores\n",
    "auc_scores = {}\n",
    "\n",
    "# Evaluate models\n",
    "for name, model in models.items():\n",
    "    # Select the appropriate features for each model\n",
    "    if 'Minimal' in name:\n",
    "        features = features_minimal\n",
    "    elif 'Moderate' in name:\n",
    "        features = features_moderate\n",
    "    else:\n",
    "        features = features_comprehensive\n",
    "    \n",
    "    # Create a pipeline with scaling and logistic regression\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    \n",
    "    # Train model\n",
    "    pipeline.fit(X_train[features], y_train)\n",
    "    \n",
    "    # Predict probabilities\n",
    "    preds_train = pipeline.predict_proba(X_train[features])[:, 1]\n",
    "    preds_val = pipeline.predict_proba(X_val[features])[:, 1]\n",
    "    \n",
    "    # Calculate AUC\n",
    "    auc_train = roc_auc_score(y_train, preds_train)\n",
    "    auc_val = roc_auc_score(y_val, preds_val)\n",
    "    \n",
    "    # Store AUC scores\n",
    "    auc_scores[name] = {'AUC Train': auc_train, 'AUC Validation': auc_val}\n",
    "\n",
    "# Print AUC scores for all models\n",
    "for model_name, scores in auc_scores.items():\n",
    "    print(f\"{model_name} - AUC Train: {scores['AUC Train']}, AUC Validation: {scores['AUC Validation']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
